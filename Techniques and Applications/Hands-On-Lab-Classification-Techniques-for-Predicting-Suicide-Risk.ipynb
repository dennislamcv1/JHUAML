{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4991df",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"JHU.png\" width=\"200\" alt=\"Johns Hopkins University logo\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0f7db",
   "metadata": {},
   "source": [
    "# Hands-On Lab: Classification Techniques for Predicting Suicide Risk\n",
    "\n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "### Overview:\n",
    "\n",
    "This lab focuses on building a classification model to predict high suicide risk using various features. It involves loading and preprocessing the dataset, applying feature engineering techniques, and developing a Random Forest classifier to categorize suicide risk levels. The model's performance is assessed, and feature importance is analyzed to identify the key factors contributing to the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf489d0c",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "\n",
    "- **Understand Data Exploration:** Learn how to examine and visualize data distributions and correlations to gain insights from the dataset.\n",
    "- **Preprocess Data:** Acquire skills in cleaning and preparing data for machine learning, including handling missing values and encoding categorical variables.\n",
    "- **Feature Engineering:** Learn how to create and utilize binary target variables for solving classification problems.\n",
    "- **Build Classification Models:** Develop a Random Forest classifier, understanding the process of training and evaluating the model.\n",
    "- **Evaluate Model Performance:** Assess model accuracy and interpret evaluation metrics such as confusion matrices and classification reports to understand model effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf58ed0",
   "metadata": {},
   "source": [
    "## Building and Evaluating the Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14170f08",
   "metadata": {},
   "source": [
    "### Step 1: Data Import and Initial Exploration\n",
    "In this step, we will import the necessary libraries, load the dataset, and examine its structure. This initial exploration helps us understand the data and prepares us for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd713f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Suicide Rates.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1113dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2d0a8",
   "metadata": {},
   "source": [
    "### Step 2. Exploratory Data Analysis (EDA): Visualizing Suicide Rates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba1ad9",
   "metadata": {},
   "source": [
    "In this section, we will start by analyzing the distribution of suicide rates per 100k population, grouped by country, using a boxplot. This visualization will help us understand the variability, spread, and central tendencies of suicide rates across different countries, allowing us to identify any potential outliers and compare suicide rates between nations more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the 'suicides/100k pop' distribution grouped by 'country'\n",
    "plt.figure(figsize=(14, 12))  # Increased figure size for better readability\n",
    "sns.boxplot(x='suicides/100k pop', y='country', data=df, showfliers=False)\n",
    "plt.title('Suicides per 100k Population by Country')\n",
    "plt.xlabel('Suicides per 100k Population')\n",
    "plt.ylabel('Country')\n",
    "\n",
    "# Reduce font size of y-axis labels\n",
    "plt.yticks(fontsize=8)\n",
    "\n",
    "# Automatically adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f1e30",
   "metadata": {},
   "source": [
    "> **Note**: Generating the box plot may take a few moments. Please be patient while the visualization is being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3dcbc",
   "metadata": {},
   "source": [
    "We have analyzed the distribution of suicide rates per 100k population by country using a boxplot. Next, please use various types of plots to further visualize and explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fc12a",
   "metadata": {},
   "source": [
    "### Experiment with Different Visualizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4e624",
   "metadata": {},
   "source": [
    "**1. Plot a histogram to show the distribution of suicide rates across different countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b40f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "plt.figure(figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd925e",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "sns.histplot(df['suicides/100k pop'], bins=30, kde=True)\n",
    "plt.title('Distribution of Suicide Rates per 100k Population')\n",
    "plt.xlabel('Suicides per 100k Population')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show() \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849760d",
   "metadata": {},
   "source": [
    "**2. Calculate and visualize the average suicide rate for each country using a bar plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b87364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "average_suicides = df.groupby('country')['suicides/100k pop'].mean().sort_values()\n",
    "\n",
    "\n",
    "# Adjust font size for y-axis labels to prevent overlap\n",
    "\n",
    "\n",
    "# Automatically adjust the layout to prevent overlapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e0158",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "average_suicides = df.groupby('country')['suicides/100k pop'].mean().sort_values()\n",
    "plt.figure(figsize=(14, 10))  # Increased figure size\n",
    "average_suicides.plot(kind='barh')\n",
    "plt.title('Average Suicide Rates per 100k Population by Country')\n",
    "plt.xlabel('Average Suicides per 100k Population')\n",
    "plt.ylabel('Country')\n",
    "\n",
    "# Adjust font size for y-axis labels to prevent overlap\n",
    "plt.yticks(fontsize=8)\n",
    "\n",
    "# Automatically adjust the layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ddcc2c",
   "metadata": {},
   "source": [
    "**3. Explore the distribution of suicide rates across different age groups using a violin plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b243220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1c173",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(x='age', y='suicides/100k pop', data=df)\n",
    "plt.title('Distribution of Suicide Rates per 100k Population by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Suicides per 100k Population')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show() \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2818c7",
   "metadata": {},
   "source": [
    "### Step 3. Correlation Analysis\n",
    "In this step, analyze the correlations between 'suicides/100k pop' and other features to identify which factors are most strongly associated with suicide rates. This analysis will help you understand the key influences on our target variable and how different factors relate to suicide rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c366fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for numeric variables\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Extract the correlation of the dependent variable 'suicides/100k pop' with other variables\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7379fc",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "suicides_corr = correlation_matrix['suicides/100k pop'].sort_values(ascending=False)\n",
    "print(\"Correlation with 'suicides/100k pop':\\n\", suicides_corr) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d710c8",
   "metadata": {},
   "source": [
    "### Insight from Correlation Analysis:\n",
    "\n",
    "The correlation analysis provides the following insights into how different features relate to the target variable 'suicides/100k pop':\n",
    "\n",
    "- suicides_no: Shows a moderate positive relationship, indicating that as the number of suicides increases, the suicide rate per 100k population also rises.\n",
    "- HDI for year: Displays a weak positive relationship, suggesting that the Human Development Index has a limited influence on suicide rates.\n",
    "- Population: Indicates a very weak relationship, implying that the total population has minimal impact on suicide rates.\n",
    "- GDP per capita: Shows an extremely weak relationship, suggesting that GDP per capita has little effect on suicide rates.\n",
    "- Year: Reveals a slight negative relationship, indicating a minor decrease in suicide rates over time.\n",
    "\n",
    "These insights help identify which features have a stronger or weaker relationship with suicide rates, guiding feature selection and model interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95aebb",
   "metadata": {},
   "source": [
    "### Step 4. Data Preprocessing\n",
    "In this step, you need to clean and prepare the data for modeling. This involves handling missing values, encoding categorical variables, and scaling numerical features. Proper preprocessing is crucial to ensure that your data is suitable for building and training an effective classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data_cleaned = df.drop(columns=['country-year', 'suicides/100k pop', 'HDI for year'])\n",
    "\n",
    "# Handle missing values (dropping rows with missing values)\n",
    "data_cleaned = data_cleaned.dropna()\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76f0ba",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "label_encoder = LabelEncoder()\n",
    "for column in ['country', 'sex', 'age', 'generation']:\n",
    "    data_cleaned[column] = label_encoder.fit_transform(data_cleaned[column])\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a74ad",
   "metadata": {},
   "source": [
    "After handling categorical variables and dropping unnecessary columns, the next step is to address numeric columns that are stored as strings. Convert these columns to float types by removing any non-numeric characters, such as commas. This ensures that all numerical data is in the appropriate format for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f549d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns stored as strings to floats (removing commas)\n",
    "non_numeric_columns = data_cleaned.columns[data_cleaned.dtypes == 'object']\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e47cb7",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "for column in non_numeric_columns:\n",
    "    try:\n",
    "        data_cleaned[column] = data_cleaned[column].replace({',': ''}, regex=True).astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Skipping column: {column}\")\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3f28d",
   "metadata": {},
   "source": [
    "Once the data is cleaned and encoded, scaling the numerical features is often beneficial. Scaling standardizes the range of feature values, which can enhance the performance and convergence speed of machine learning algorithms. In this step, use the `StandardScaler` to scale the `population` and `gdp_per_capita (S)` features, ensuring they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a56fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features (optional but often useful for classifiers)\n",
    "scaler = StandardScaler()\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad9a3d",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "data_cleaned[['population', 'gdp_per_capita ($)']] = scaler.fit_transform(data_cleaned[['population', 'gdp_per_capita ($)']]) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the preprocessed dataset\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f29703",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "data_cleaned.head() \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c60016",
   "metadata": {},
   "source": [
    "With the numerical features scaled, you can now proceed to define your target variable. Create a binary variable `high_risk` to classify the data based on whether the number of suicides exceeds a threshold of 20. This target variable will help guide your classification model in predicting high-risk cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e40037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary target variable (1 if suicides_no > 20, else 0)\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ee113",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "data_cleaned['high_risk'] = (data_cleaned['suicides_no'] > 20).astype(int) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93deaca9",
   "metadata": {},
   "source": [
    "Having defined the binary target variable `high_risk`—where 1 represents a high number of suicides (greater than 20) and 0 represents a lower number—you are now ready to split the data into training and testing sets. This split is essential for training your classification model and evaluating its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8794c",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "X = data_cleaned.drop(columns=['suicides_no', 'high_risk'])\n",
    "y = data_cleaned['high_risk']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52e81d",
   "metadata": {},
   "source": [
    "With the data split into training and testing sets, you can now proceed to train your classification model. Use the training data to fit the model, and then evaluate its performance on the testing data. This process allows you to assess how well the model generalizes to new, unseen data and make any necessary adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a Random Forest model\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13943c49",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820c10c",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model\n",
    "After training the Random Forest model on the training data, the next step is to evaluate its performance. Use the testing set to make predictions and assess the model’s accuracy, along with other performance metrics such as precision, recall, and F1-score. This evaluation helps you understand how well the model classifies new data and whether it meets your objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3267ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e796b",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2cb14d",
   "metadata": {},
   "source": [
    "With the model evaluated and performance metrics obtained, the next step is to analyze feature importance. Random Forest models offer insights into which features have the most significant impact on predictions. By examining feature importance, you can identify the key factors influencing suicide risk, guiding further analysis and model refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02016676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from the Random Forest model\n",
    "feature_importances = model.feature_importances_\n",
    "#Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52103b40",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    " \n",
    "```python\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "print(importance_df.sort_values(by='Importance', ascending=False)) \n",
    "```\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8de65",
   "metadata": {},
   "source": [
    "The feature importance analysis reveals which features most significantly impact predicting suicide risk. Features with higher importance scores are crucial for the model, while those with lower scores contribute less. This understanding helps in focusing on key features and refining the model for improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af33b01",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "In this lab, you built and evaluated a Random Forest model to predict high-risk suicide rates. After preprocessing the data and training the model, you achieved strong performance and identified key features that significantly impact predictions. This insight will guide further model refinement and improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
