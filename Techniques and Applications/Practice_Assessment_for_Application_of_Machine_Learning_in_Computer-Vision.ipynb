{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a40f6b1",
   "metadata": {},
   "source": [
    "<center>\n",
    " <img src = \"JHU.png\"  width=\"200\" alt=\"Johns Hopkins University logo\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4864672",
   "metadata": {},
   "source": [
    "# Hands-on Practice Assessment for Application of Machine Learning in Computer Vision\n",
    "\n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "### Overview:\n",
    "\n",
    "In this practice assignment, you will tackle a series of problems that are designed to reinforce the concepts you've learned in this module. These problems will help you apply your knowledge and develop your skills further.\n",
    "\n",
    "As you work through the assignment, you might encounter questions or challenges where you need additional clarification. If so, you can access the hidden solutions for guidance by clicking the \"Click Here\" option. This feature is available to assist you in understanding the material better and ensuring you complete the assignment effectively.\n",
    "\n",
    "Be sure to use the solutions as a resource to enhance your learning, but try to solve the problems on your own first to maximize your practice experience. \n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "* Data Exploration and Feature Analysis\n",
    "* Unsupervised Clustering Techniques\n",
    "* Supervised Learning and Model Development\n",
    "* Impact of Training Data Size on Model Accuracy\n",
    "* Visualization and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c520be",
   "metadata": {},
   "source": [
    "#### Problem 1: Pick the Iris dataset of the Scikit-learn datasets for classification which is included in the library (i.e. the dataset can be loaded with datasets.load_) and find out the following:\n",
    "\n",
    "- The number of data points. \n",
    "- The number of features and their types. \n",
    "- The number and name of categories (i.e. the target field). \n",
    "- The mean (or mode if nominal) of the first two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a796b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris Dataset\n",
    "# You can load the Iris dataset using Scikit-learn with the following code:\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f4847",
   "metadata": {},
   "source": [
    "#### i) The number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159128ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a69af",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To find the number of features and their types:\n",
    "    \n",
    "```\n",
    "n_samples = iris.data.shape[0]\n",
    "n_samples\n",
    "print(n_samples)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643677d",
   "metadata": {},
   "source": [
    "#### ii. Number of Features and Their Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5b4b6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To find the number of features and their types:\n",
    "    \n",
    "```\n",
    "n_features = iris.data.shape[1]\n",
    "feature_names = iris.feature_names\n",
    "feature_names\n",
    "print(feature_names)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe1d49",
   "metadata": {},
   "source": [
    "#### iii. Number and Name of Categories (Target Field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed76073",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>   \n",
    "#To find the number and name of categories:\n",
    "    \n",
    "```\n",
    "target_names = iris.target_names\n",
    "n_classes = len(target_names)\n",
    "print(n_classes) \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c86391",
   "metadata": {},
   "source": [
    "#### iv. Mean of the First Two Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9883cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f99c1c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To calculate the mean of the first two features (Sepal length and Sepal width):\n",
    "    \n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "mean_sepal_length = np.mean(iris.data[:, 0])\n",
    "mean_sepal_width = np.mean(iris.data[:, 1])\n",
    "\n",
    "print(mean_sepal_length)\n",
    "print(mean_sepal_width)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed4e27",
   "metadata": {},
   "source": [
    "#### Problem 2:  Next, locate the Wine dataset, load it, and explore it to find out the same characteristics [as in Problem #2 , parts i) to iv) ] once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the wine Dataset\n",
    "#You can load the wine dataset using Scikit-learn with the following code:\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0767c26",
   "metadata": {},
   "source": [
    "#### i. Number of Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dc839",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To find the number of data points (or samples) in the dataset:\n",
    "    \n",
    "```\n",
    "n_samples_wine = wine.data.shape[0]\n",
    "print(f\"Number of data points: {n_samples_wine}\")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c11e08",
   "metadata": {},
   "source": [
    "#### ii. Number of Features and Their Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b131fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88eb2c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To find the number of features and their types:\n",
    "    \n",
    "```\n",
    "n_features_wine = wine.data.shape[1]\n",
    "feature_names_wine = wine.feature_names\n",
    "\n",
    "print(f\"Number of features: {n_features_wine}\")\n",
    "print(f\"Feature names: {feature_names_wine}\")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef788a",
   "metadata": {},
   "source": [
    "#### iii. Number and Name of Categories (Target Field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd14c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37764ae",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To find the number and name of categories:\n",
    "    \n",
    "```\n",
    "target_names_wine = wine.target_names\n",
    "n_classes_wine = len(target_names_wine)\n",
    "\n",
    "print(f\"Category names: {target_names_wine}\")\n",
    "print(f\"Number of categories: {n_classes_wine}\")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d29ac",
   "metadata": {},
   "source": [
    "#### iv. Mean of the First Two Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f4bbd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "# To calculate the mean of the first two features (Sepal length and Sepal width):\n",
    "    \n",
    "```\n",
    "mean_first_feature = np.mean(wine.data[:, 0])\n",
    "mean_second_feature = np.mean(wine.data[:, 1])\n",
    "\n",
    "print(f\"Mean of the first feature (Alcohol): {mean_first_feature}\")\n",
    "print(f\"Mean of the second feature (Malic acid): {mean_second_feature}\")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177bd3b",
   "metadata": {},
   "source": [
    "#### Problem 3: Use the following lines of code to display feature pairs from the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "iris = sklearn.datasets.load_iris()\n",
    "iris_df = pd.DataFrame(\n",
    "data= np.c_[iris.data, [iris.target_names[v] for v in iris.target]],\n",
    "columns= iris.feature_names + ['species'])\n",
    "cols = iris_df.columns.drop('species')\n",
    "iris_df[cols] = iris_df[cols].apply(pd.to_numeric)\n",
    "g = sns.pairplot(iris_df, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce354db",
   "metadata": {},
   "source": [
    "#### i. From the above plots, which feature(s) shows the most promising separation power for machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d2d26",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "\n",
    "From the pairplot provided, the features that show the most promising separation power between the different species (Setosa, Versicolor, and Virginica) are:\n",
    "\n",
    "1. **Petal length (cm)**\n",
    "2. **Petal width (cm)**\n",
    "\n",
    "These features display clear distinctions between the species, with Setosa being completely separated from Versicolor and Virginica. Versicolor and Virginica show some overlap, but petal length and width still provide significant separation, making them strong candidates for features in a machine learning model.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc506ef",
   "metadata": {},
   "source": [
    "#### ii. Now plot the features of the Wine dataset in question 2. When there are too many features, it is possible to switch the dataset or update your code (pandas Dataframe line) to look at only a certain number of features at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1797adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here!\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert the dataset into a Pandas DataFrame\n",
    "\n",
    "# Map the target to the wine classes for easier visualization\n",
    "\n",
    "# Select a subset of features for pairplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cc83a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "\n",
    "```\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert the dataset into a Pandas DataFrame\n",
    "wine_df = pd.DataFrame(data=np.c_[wine.data, wine.target], columns=wine.feature_names + ['target'])\n",
    "\n",
    "# Map the target to the wine classes for easier visualization\n",
    "wine_df['target'] = wine_df['target'].map(dict(enumerate(wine.target_names)))\n",
    "\n",
    "# Select a subset of features for pairplot\n",
    "subset_features = ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'target']\n",
    "sns.pairplot(wine_df[subset_features], hue='target')\n",
    "    \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277e36c",
   "metadata": {},
   "source": [
    "#### Consider the Iris dataset, refer to the plots in the previous question, and discuss/think/outline an unsupervised approach to group the dataset into non-overlapping clusters :\n",
    "\n",
    "- Which features would you use?\n",
    "- Are three clusters obvious from the plots?\n",
    "- What about four clusters? Either roughly mark them manually (i.e. indicating cutoff\n",
    "    thresholds) on a few plots if possible, or specify their ranges (i.e. provide the range\n",
    "    of values per cluster per each feature you’ve chosen to include).\n",
    "- For this problem, is there any relation between classification and clustering since the\n",
    "    labels are already given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8ae84",
   "metadata": {},
   "source": [
    "#### i. Which features would you use?\n",
    "\n",
    "Given the separation power observed in the previous pairplot, the most effective features for clustering are:\n",
    "\n",
    "- **Petal length (cm)**\n",
    "- **Petal width (cm)**\n",
    "\n",
    "These two features provide the clearest distinction between the species, making them ideal candidates for clustering.\n",
    "\n",
    "#### ii. Are three clusters obvious from the plots?\n",
    "\n",
    "Yes, three clusters are fairly obvious from the plots. \n",
    "\n",
    "- **Setosa** is completely separated from the other two species (Versicolor and Virginica) when looking at petal length and petal width.\n",
    "- **Versicolor** and **Virginica** overlap but still form distinguishable clusters.\n",
    "\n",
    "This natural separation suggests that a clustering algorithm like K-Means with `k=3` would likely perform well.\n",
    "\n",
    "#### iii. What about four clusters?\n",
    "\n",
    "Creating four clusters is more challenging with the Iris dataset because the natural structure suggests three clusters corresponding to the three species. However, it’s possible to hypothesize four clusters by introducing an artificial split within one of the existing clusters (likely between Versicolor and Virginica). \n",
    "\n",
    "To manually mark four clusters:\n",
    "- **Cluster 1 (Setosa)**: \n",
    "  - Petal length: 1.0 - 2.0 cm\n",
    "  - Petal width: 0.1 - 0.6 cm\n",
    "- **Cluster 2 (Versicolor 1)**:\n",
    "  - Petal length: 3.0 - 4.5 cm\n",
    "  - Petal width: 1.0 - 1.5 cm\n",
    "- **Cluster 3 (Versicolor 2)**:\n",
    "  - Petal length: 4.5 - 5.5 cm\n",
    "  - Petal width: 1.5 - 2.0 cm\n",
    "- **Cluster 4 (Virginica)**:\n",
    "  - Petal length: 5.5 - 7.0 cm\n",
    "  - Petal width: 1.5 - 2.5 cm\n",
    "\n",
    "This artificial split doesn’t correspond to a biological reality but could be used to explore the effects of forcing a four-cluster solution.\n",
    "\n",
    "#### iv. Is there any relation between classification and clustering since the labels are already given?\n",
    "\n",
    "Yes, there is a strong relation between classification and clustering in this context:\n",
    "\n",
    "- **Classification** is a supervised learning approach where the model is trained on labeled data. For the Iris dataset, a classifier would learn to predict the species label based on the provided features.\n",
    "  \n",
    "- **Clustering** is an unsupervised learning approach where the algorithm tries to group the data into clusters without knowing the labels in advance.\n",
    "\n",
    "Since the labels (species) are already given, clustering can be evaluated by how well it recovers these labels. For example, a clustering algorithm that correctly identifies the three species would have formed clusters that closely match the original labels. However, clustering does not inherently need the labels and would typically be used in scenarios where the labels are unknown.\n",
    "\n",
    "In this case, the relationship between classification and clustering can be used to evaluate the clustering approach by comparing the clusters to the actual species labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30166857",
   "metadata": {},
   "source": [
    "#### Problem 4: Using the scikit-learn class descriptions, develop machine learning models for the Iris dataset using the following classification algorithms:\n",
    "\n",
    "- Naive Bayes and Decision Trees.\n",
    "- Test and evaluate the performance of these models.\n",
    "- Plot the model accuracy with respect to different training sizes using a line graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62e870",
   "metadata": {},
   "source": [
    "#### Step 1: Load the Data and Split It\n",
    "First, we'll load the Iris dataset and prepare it for training. We need to split this data into two parts: one for training the model and another for testing its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ceabae",
   "metadata": {},
   "source": [
    "#### Step 2: Train the Models on Different Amounts of Data\n",
    "We'll use two types of models: Naive Bayes and Decision Trees. To see how much training data affects their accuracy, we'll gradually increase the size of the training set (from 1% to 100% of the data). For each size, we'll train the models and check how well they predict the species of flowers in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f744a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Write your solution here!\n",
    "# Create the classifiers\n",
    "nb_classifier = GaussianNB()\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Arrays to hold accuracy results\n",
    "\n",
    "    \n",
    "    # Train and test Naive Bayes\n",
    "\n",
    "    \n",
    "    # Train and test Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c004658",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "    \n",
    "```\n",
    "# Create the classifiers\n",
    "nb_classifier = GaussianNB()\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Arrays to hold accuracy results\n",
    "training_sizes = np.arange(0.01, 1.01, 0.05)  # 1% to 100% of the data\n",
    "nb_accuracies = []\n",
    "dt_accuracies = []\n",
    "\n",
    "for size in training_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, shuffle=True)\n",
    "    \n",
    "    # Train and test Naive Bayes\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    nb_accuracy = accuracy_score(y_test, nb_classifier.predict(X_test))\n",
    "    nb_accuracies.append(nb_accuracy)\n",
    "    \n",
    "    # Train and test Decision Tree\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    dt_accuracy = accuracy_score(y_test, dt_classifier.predict(X_test))\n",
    "    dt_accuracies.append(dt_accuracy)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bada5b1",
   "metadata": {},
   "source": [
    "#### Step 3: Plot the Results\n",
    "Finally, we'll plot the accuracy of each model as the training size increases. This helps us visualize how much data each model needs to perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c446f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Write your solution here!\n",
    "plt.plot(training_sizes * 100, nb_accuracies, label='Naive Bayes', marker='o')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d132d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click here to view/hide solution</summary>\n",
    "\n",
    "    \n",
    "```\n",
    "plt.plot(training_sizes * 100, nb_accuracies, label='Naive Bayes', marker='o')\n",
    "plt.plot(training_sizes * 100, dt_accuracies, label='Decision Tree', marker='s')\n",
    "\n",
    "plt.xlabel('Training Set Size (%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy vs. Training Set Size')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bbdee",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "- **Shuffling the data** is important to ensure that each training and test set is representative of the entire dataset.\n",
    "- **Naive Bayes** often performs well with smaller datasets and tends to be more stable but may plateau as training data increases.\n",
    "- **Decision Trees** may perform better initially but can overfit, meaning they might not generalize well if the training data is too small or too specific.\n",
    "- **More training data** generally improves accuracy, but there is a point where adding more data won’t significantly increase performance. This is seen as a plateau in the accuracy plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0a200",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "This assignment provides a hands-on approach to understanding key machine learning concepts through practical problems. It begins with defining fundamental terms, followed by exploring the Iris dataset using pair plots to visualize feature separability. Then outline strategies for clustering the data and apply supervised learning techniques using Naive Bayes and Decision Trees. The final problem focuses on analyzing how increasing the training dataset size impacts model performance, helping to understand the importance of data size and the potential for performance plateaus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
